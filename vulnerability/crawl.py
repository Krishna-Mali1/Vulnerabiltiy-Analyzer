#!/usr/bin/env python
import re
import  urllib.parse as urlparse

import requests
from bs4 import BeautifulSoup

class Crawl:
    def __init__(self,url,ignore_links):
        self.session = requests.session()
        self.target_url = url
        self.target_link = []
        self.link_to_ignore = ignore_links

    def extract_link_url(self,url):
        response = self.session.get(url)
        return re.findall(r'href=["\'](.*?)["\']', response.content.decode(errors="ignore"))


    def crawl(self,url=None): #default value to none
        if url is None:
            url = self.target_url
        href_link = self.extract_link_url(url)

        for link in href_link:
            link = urlparse.urljoin(url, link)  # convert relative link to full url

            if '#' in link:
                link = link.split("#")[0]
            if self.target_url in link and link not in self.target_link and link not  in self.link_to_ignore:
                self.target_link.append(link)
                print(link)
                self.crawl(link)

    def extract_fourms(self,url):
        response = self.session.get(url)

        parsed_html = BeautifulSoup(response.content,"html.parser")
        return parsed_html.find_all("form")

    def submit_form(self,form,value,url):
        action = form.get("action")
        post_url = urlparse.urljoin(url, action)
        method = form.get("method")

        input_list = form.find_all("input")
        post_data = {}
        for input in input_list:
            input_name = input.get("name")
            input_type = input.get("type")
            input_value = input.get("value")
            if input_type == "text":
                input_value = value
            post_data[input_name] = input_value
        if method == "post":
            return self.session.post(post_url, data=post_data)
        return  self.session.get(post_url,params=post_data)


